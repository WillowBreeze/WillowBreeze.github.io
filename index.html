<html>
<link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
<body class="font-sans leading-relaxed tracking-wide flex flex-col">
  <header id="home" class="relative h-screen bg-cover bg-center" style="background-image: url('https://picsum.photos/1600/900');">
    <div class="absolute inset-0 bg-black opacity-50"></div>
    <div class="absolute inset-0 flex flex-col justify-center items-center text-white">
      <h1 class="text-5xl font-bold">Jiaqi Wang</h1>
      <p class="text-2xl mt-4">Research Scientist</p>
      <p class="mt-2">701 Yunjin Road, Xuhui, Shanghai, China</p>
      <p class="mt-2">+86) 18604792323 | wjqdev@gmail.com | <a href="https://github.com/myownskyW7" target="_blank">github:myownskyW7</a> | <a href="https://scholar.google.com/citations?user=GDvt570AAAAJ" target="_blank">google scholar</a></p>
    </div>
  </header>

  <section id="profile" class="py-20 bg-gray-100">
    <div class="container mx-auto flex flex-col md:flex-row items-center">
      <img src="https://source.unsplash.com/random/300x300/?portrait" alt="Profile Picture" class="rounded-full w-48 h-48 mb-6 md:mb-0 md:mr-6">
      <div>
        <h2 class="text-3xl font-bold mb-4">Profile</h2>
        <p>Jiaqi Wang is a Research Scientist at Shanghai AI Laboratory. Before that, he received his Ph.D. at Multimedia Laboratory (MMLab) of The Chinese University of Hong Kong (CUHK), supervised by Prof. Dahua Lin. He also works closely with Prof. Chen Change Loy.</p>
        <p>His research interests focus on Multimodal Learning, Visual Perception, and AI Content Creation in both 2D and 3D open worlds.</p>
        <p>We have opening positions for research interns (undergraduate, master, Ph.D. and gap year students are all welcomed) and full-time researchers. Please drop me an e-mail (wjqdev@gmail.com) if you are interested.</p>
      </div>
    </div>
  </section>

  <section id="education" class="py-20 bg-white">
    <div class="container mx-auto">
      <h2 class="text-3xl font-bold mb-8 text-center">Education</h2>
      <div class="relative">
        <div class="border-l-2 border-gray-400 pl-8">
          <div class="mb-8">
            <div class="flex items-center mb-2">
              <div class="bg-gray-400 w-8 h-8 rounded-full flex items-center justify-center">
                <img src="https://source.unsplash.com/random/40x40/?university" alt="Sun Yat-sen University Logo" class="w-6 h-6">
              </div>
              <div class="ml-4">
                <h3 class="text-xl font-semibold">Sun Yat-Sen University</h3>
                <p>B.Eng. in Software Engineering</p>
                <p>Aug. 2013 - Jun. 2017</p>
              </div>
            </div>
            <p>Guangzhou City, China</p>
          </div>
          <div class="mb-8">
            <div class="flex items-center mb-2">
              <div class="bg-gray-400 w-8 h-8 rounded-full flex items-center justify-center">
                <img src="https://source.unsplash.com/random/40x40/?university" alt="CUHK Logo" class="w-6 h-6">
              </div>
              <div class="ml-4">
                <h3 class="text-xl font-semibold">The Chinese University of Hong Kong (CUHK)</h3>
                <p>Ph.D. in Information Engineering</p>
                <p>Aug. 2017 - Nov. 2021</p>
              </div>
            </div>
            <p>Hong Kong</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section id="experience" class="py-20 bg-gray-100">
    <div class="container mx-auto">
      <h2 class="text-3xl font-bold mb-8 text-center">Work Experience</h2>
      <div class="relative">
        <div class="border-l-2 border-gray-400 pl-8">
          <div class="mb-8 hover:bg-gray-200 p-4 rounded">
            <div class="flex items-center mb-2">
              <div class="bg-gray-400 w-8 h-8 rounded-full flex items-center justify-center">
                <img src="https://source.unsplash.com/random/40x40/?company" alt="Shanghai AI Laboratory Logo" class="w-6 h-6">
              </div>
              <div class="ml-4">
                <h3 class="text-xl font-semibold">Shanghai AI Laboratory</h3>
                <p>Research Scientist & Team Leader</p>
                <p>Nov. 2021 - Now</p>
              </div>
            </div>
            <p>Shanghai, China</p>
          </div>
          <div class="mb-8 hover:bg-gray-200 p-4 rounded">
            <div class="flex items-center mb-2">
              <div class="bg-gray-400 w-8 h-8 rounded-full flex items-center justify-center">
                <img src="https://source.unsplash.com/random/40x40/?company" alt="MSRA Logo" class="w-6 h-6">
              </div>
              <div class="ml-4">
                <h3 class="text-xl font-semibold">Microsoft Research Asia (MSRA)</h3>
                <p>Research Intern</p>
                <p>Jul. 2016 - Feb. 2017</p>
              </div>
            </div>
            <p>Beijing, China</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section id="honors" class="py-20 bg-white">
    <div class="container mx-auto">
      <h2 class="text-3xl font-bold mb-8 text-center">Honors & Awards</h2>
      <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
        <div class="bg-gray-100 p-6 rounded shadow-lg transition transform hover:scale-105">
          <h3 class="text-xl font-semibold mb-2">2023 Award Candidate, CVPR 2023</h3>
        </div>
        <div class="bg-gray-100 p-6 rounded shadow-lg transition transform hover:scale-105">
          <h3 class="text-xl font-semibold mb-2">2019 1st place entry in COCO 2019 Object Detection Challenge (without external data), Team: MMDet, Team Leader</h3>
        </div>
        <div class="bg-gray-100 p-6 rounded shadow-lg transition transform hover:scale-105">
          <h3 class="text-xl font-semibold mb-2">2018 1st place entry in COCO 2018 Object Detection Challenge, Team: MMDet, Core Member</h3>
        </div>
      </div>
    </div>
  </section>

  <section id="projects" class="py-20 bg-gray-100">
    <div class="container mx-auto">
      <h2 class="text-3xl font-bold mb-8 text-center">Projects</h2>
      <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
        <div class="bg-white p-6 rounded shadow-lg overflow-hidden">
          <img src="https://source.unsplash.com/random/400x300/?code" alt="InternLM-XComposer" class="w-full h-48 object-cover">
          <div class="mt-4">
            <h3 class="text-xl font-semibold">InternLM-XComposer</h3>
            <p class="mt-2">Project Leader 2023 - now</p>
            <p class="mt-2">InternLM-XComposer is one of the most influential open-source Multimodal Large Model series, with over 1.9k stars on GitHub and more than 300k downloads on Hugging Face.</p>
            <a href="https://github.com/InternLM/InternLM-XComposer" target="_blank" class="text-blue-500 mt-2 block">Github: InternLM-XComposer</a>
            <a href="/path/to/technical_report.pdf" target="_blank" class="text-blue-500 mt-2 block">Technical Report</a>
          </div>
        </div>
        <div class="bg-white p-6 rounded shadow-lg overflow-hidden">
          <img src="https://source.unsplash.com/random/400x300/?code" alt="MMDetection" class="w-full h-48 object-cover">
          <div class="mt-4">
            <h3 class="text-xl font-semibold">MMDetection</h3>
            <p class="mt-2">Second author and Core Developer 2018 - now</p>
            <p class="mt-2">MMDetection is one of the most popular object detection codebase. It has more than 25k stars on Github.</p>
            <a href="https://github.com/open-mmlab/mmdetection" target="_blank" class="text-blue-500 mt-2 block">Github Link</a>
            <a href="/path/to/technical_report.pdf" target="_blank" class="text-blue-500 mt-2 block">Technical Report</a>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section id="publications" class="py-20 bg-white">
    <div class="container mx-auto">
      <h2 class="text-3xl font-bold mb-8 text-center">Publications</h2>
      <div class="relative">
        <div class="w-full mx-auto">
          <table class="min-w-full bg-white">
            <thead>
              <tr>
                <th class="py-2 px-4 border-b">Title</th>
                <th class="py-2 px-4 border-b">Conference</th>
                <th class="py-2 px-4 border-b">Co-authors</th>
                <th class="py-2 px-4 border-b">Year</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td class="py-2 px-4 border-b">CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers</td>
                <td class="py-2 px-4 border-b">ICML 2024 Poster</td>
                <td class="py-2 px-4 border-b">D. Shi, C. Tao, A. Rao, Z. Yang, C. Yuan, J. Wang</td>
                <td class="py-2 px-4 border-b">2024</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">GPT4Point: A Unified Framework for Point-Language Understanding and Generation</td>
                <td class="py-2 px-4 border-b">CVPR 2024 Highlight</td>
                <td class="py-2 px-4 border-b">Z. Qi, Y. Fang, Z. Sun, X. Wu, T. Wu, J. Wang, D. Lin, H. Zhao</td>
                <td class="py-2 px-4 border-b">2024</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">Alpha-CLIP: A clip model focusing on wherever you want</td>
                <td class="py-2 px-4 border-b">CVPR 2023 Poster</td>
                <td class="py-2 px-4 border-b">Z. Sun, Y. Fang, T. Wu, P. Zhang, Y. Zang, S. Kong, Y. Xiong, D. Lin, J. Wang</td>
                <td class="py-2 px-4 border-b">2023</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation</td>
                <td class="py-2 px-4 border-b">CVPR 2023 Award Candidate</td>
                <td class="py-2 px-4 border-b">T. Wu, J. Zhang, X. Fu, Y. Wang, J. Ren, L. Pan, W. Wu, L. Yang, J. Wang, C. Qian, D. Lin, Z. Liu</td>
                <td class="py-2 px-4 border-b">2023</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation</td>
                <td class="py-2 px-4 border-b">AAAI 2022 Poster</td>
                <td class="py-2 px-4 border-b">Z. Yang, J. Wang, Y. Tang, K. Chen, H. Zhao, P. H. S. Torr</td>
                <td class="py-2 px-4 border-b">2022</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">Pyskl: Towards good practices for skeleton action recognition</td>
                <td class="py-2 px-4 border-b">MM 2022</td>
                <td class="py-2 px-4 border-b">H. Duan, J. Wang, K. Chen, D. Lin</td>
                <td class="py-2 px-4 border-b">2022</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">Dense Distinct Query for End-to-End Object Detection</td>
                <td class="py-2 px-4 border-b">CVPR 2023 Poster</td>
                <td class="py-2 px-4 border-b">S. Zhang, X. Wang, J. Wang, J. Pang, C. Lyu, W. Zhang, P. Luo, K. Chen</td>
                <td class="py-2 px-4 border-b">2023</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">BUOL: A Bottom-Up Framework with Occupancy-aware Lifting for Panoptic 3D Scene Reconstruction From A Single Image</td>
                <td class="py-2 px-4 border-b">CVPR 2023 Poster</td>
                <td class="py-2 px-4 border-b">T. Chu, P. Zhang, Q. Liu, J. Wang</td>
                <td class="py-2 px-4 border-b">2023</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">HyperDreamer: Hyper-Realistic 3D Content Generation and Editing from a Single Image</td>
                <td class="py-2 px-4 border-b">SIGGRAPH Asia 2023 Poster</td>
                <td class="py-2 px-4 border-b">T. Wu, Z. Li, S. Yang, P. Zhang, X. Pan, J. Wang, Z. Liu, D. Lin</td>
                <td class="py-2 px-4 border-b">2023</td>
              </tr>
              <tr>
                <td class="py-2 px-4 border-b">VIGC: Visual Instruction Generation and Correction</td>
                <td class="py-2 px-4 border-b">AAAI 2024 Poster</td>
                <td class="py-2 px-4 border-b">B. Wang, F. Wu, X. Han, J. Peng, H. Z
